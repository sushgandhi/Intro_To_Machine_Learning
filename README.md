# ML Jump Start

#### Disclaimer : I am not an expert, just a noob

This Repo contains collated notes from the following Sources

- Prof. Andrew Ng's  Machine Learning Course on [Coursera](https://www.coursera.org/learn/machine-learning)
- Brilliant book ["Data Science from Scratch"](http://shop.oreilly.com/product/0636920033400.do)
- [Kaggle Learn](https://www.kaggle.com/learn/overview)
- Udacity's following courses -
	- Statistics - [Descriptive](https://in.udacity.com/course/intro-to-descriptive-statistics--ud827) and [inferential](https://in.udacity.com/course/intro-to-inferential-statistics--ud201)
	- [Linear Algebra](https://classroom.udacity.com/courses/ud953)
	- [Intro to Machine Learning](https://in.udacity.com/course/intro-to-machine-learning--ud120)
	- [Machine Learning](https://in.udacity.com/course/machine-learning--ud262)
	- [Model Building and Validation](https://in.udacity.com/course/model-building-and-validation--ud919)
- Some parts of [Hands on Machine learning with Scikit-Learn and TensorFlow](http://shop.oreilly.com/product/0636920052289.do)
- Siraj Raval's [YouTube Channel](https://www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A/)
- Sentdex Playlist on [Machine Learning with Python](https://www.youtube.com/playlist?list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v)

Idea is that this repo can be considered as consolidated resource for getting started with machine learning.
Both Theoretical knowledge of Statistics and Machine Learning Algorithms And Practical knowledge on how to implement this using just python(Pandas and NumPy) to get complete understanding.

In most cases I have also included the starter code on how to implement using Scikit-Learn

Al the code is using Python 3.5


#### Contents -

- Introduction
	- What is Machine Learning ?
	- Things to know in Linear Algebra, Statistics, Probability
- Linear Regression (Part I)
	- Regression in One Variable
	- Model and Cost Functions
	- Gradient Descent
- Linear Regression (Part II)
	- Multi Variable Linear Regression
	- Features and Variables
	- Computing Parameters
- Logistic Regression
	- What is Logistic Regression
	- Classification and Representation
	- Cost Function and Gradient Descent
	- Other Variants of Logistic Regression
- Naive Bayes
	- what and when to use?
- Support Vector Machines (SVM)
	- what and when to use ?
- K Nearest Neighbors
- Decision Trees
- Random Forest
- Applying Concepts
	Evaluating Hypothesis
	Bias vs Variance
- Unsupervised Learning
	- Clustering
	- Dimensionality Reduction
	- PCA
- Clustering and K Means
- Feature Engineering
- Ensemble Methods
	- Bagging
	- Boosting
	- Stacking
- Gradient Boosting
	- XGBoost
	- LightGBM
- Large Scale Machine Learning and Online Learning
- Kaggle Competition Approaches
	Titanic Survival Prediction
	Amazon - Employee Access Challenge
	Instacart Market Basket Analysis
